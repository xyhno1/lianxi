{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790be32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "import net\n",
    "from hyptorch.pmath import dist_matrix\n",
    "from proxy_anchor import dataset\n",
    "from proxy_anchor.utils import calc_recall_at_k\n",
    "from sampler import UniqueClassSempler\n",
    "from proxy_anchor.dataset import CUBirds, SOP, Cars\n",
    "from proxy_anchor.dataset.Inshop import Inshop_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3f9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65eb4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/xuyunhao/datasets'\n",
    "ds = 'CUB'\n",
    "num_samples = 2\n",
    "bs = 200\n",
    "lr = 1e-5\n",
    "t = 0.2\n",
    "emb = 512\n",
    "ep = 100\n",
    "local_rank = 0\n",
    "workers = 4\n",
    "optimizer = 'adamw'\n",
    "lr_decay_step = 10\n",
    "lr_decay_gamma = 0.5\n",
    "\n",
    "model =  'resnet18'\n",
    "hyp_c = 0\n",
    "clip_r  = 2.3\n",
    "resize = 224\n",
    "crop = 224\n",
    "gpu_id = 7\n",
    "bn_freeze = 1\n",
    "freezer = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d687294",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c1f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(e0, e1, tau):\n",
    "    # x0 and x1 - positive pair\n",
    "    # tau - temperature\n",
    "    # hyp_c - hyperbolic curvature, \"0\" enables sphere mode\n",
    "    dist_e = lambda x, y: -torch.cdist(x, y, p=2)\n",
    "    \n",
    "    dist_e0 = dist_e(e0, e0)   \n",
    "    dist_e1 = dist_e(e0, e1)\n",
    "\n",
    "    bsize = e0.shape[0]\n",
    "    target = torch.arange(bsize).cuda()\n",
    "    eye_mask = torch.eye(bsize).cuda() * 1e9\n",
    "    \n",
    "    logits00 = dist_e0 / tau - eye_mask\n",
    "    logits01 = dist_e1 / tau\n",
    "    \n",
    "    logits = torch.cat([logits01, logits00], dim=1)\n",
    "    logits -= logits.max(1, keepdim=True)[0].detach()\n",
    "    loss = F.cross_entropy(logits, target)\n",
    "    stats = {\n",
    "        \"logits/min\": logits01.min().item(),\n",
    "        \"logits/mean\": logits01.mean().item(),\n",
    "        \"logits/max\": logits01.max().item(),\n",
    "        \"logits/acc\": (logits01.argmax(-1) == target).float().mean().item(),\n",
    "    }\n",
    "    return loss, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6c41a",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7b1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import hyptorch.nn as hypnn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class Resnet18(nn.Module):\n",
    "    def __init__(self,embedding_size, pretrained=True, bn_freeze = True):\n",
    "        super(Resnet18, self).__init__()\n",
    "\n",
    "        self.model = resnet18(pretrained)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_ftrs = self.model.fc.in_features\n",
    "        self.model.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.Elayer = NormLayer()\n",
    "        self.model.embedding = nn.Sequential(nn.Linear(self.num_ftrs, self.embedding_size), self.Elayer)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        if bn_freeze:\n",
    "            for m in self.model.modules():\n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eval()\n",
    "                    m.weight.requires_grad_(False)\n",
    "                    m.bias.requires_grad_(False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "\n",
    "        avg_x = self.model.gap(x)\n",
    "        max_x = self.model.gmp(x)\n",
    "\n",
    "        x = max_x + avg_x\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_e = self.model.embedding(x)\n",
    "        return x_e\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.kaiming_normal_(self.model.embedding[0].weight, mode='fan_out')\n",
    "        init.constant_(self.model.embedding[0].bias, 0)\n",
    "\n",
    "class NormLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf9d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(get_emb_f, ds_name):\n",
    "    emb_head = get_emb_f(ds_type=\"eval\")\n",
    "    recall_head = get_recall(*emb_head, ds_name)\n",
    "    return recall_head\n",
    "\n",
    "def get_recall(e, y, ds_name):\n",
    "    if ds_name == \"CUB\" or ds_name == \"Cars\":\n",
    "        k_list = [1, 2, 4, 8, 16, 32]\n",
    "    elif ds_name == \"SOP\":\n",
    "        k_list = [1, 10, 100, 1000]\n",
    "\n",
    "    dist_m = torch.empty(len(e), len(e), device=\"cuda\")\n",
    "    for i in range(len(e)):\n",
    "        dist_m[i : i + 1] = -torch.cdist(e[i : i + 1], e, p=2)\n",
    "\n",
    "    y_cur = y[dist_m.topk(1 + max(k_list), largest=True)[1][:, 1:]]\n",
    "    y = y.cpu()\n",
    "    y_cur = y_cur.float().cpu()\n",
    "    recall = [calc_recall_at_k(y, y_cur, k) for k in k_list]\n",
    "    print(recall)\n",
    "    return recall[0]\n",
    "\n",
    "def get_emb(\n",
    "    model,\n",
    "    ds,\n",
    "    path,\n",
    "    ds_type=\"eval\",\n",
    "    world_size=1,\n",
    "    num_workers=8,\n",
    "):\n",
    "    eval_tr = dataset.utils.make_transform(\n",
    "        is_train = True, \n",
    "        is_inception = (model == 'bn_inception')\n",
    "    )\n",
    "    ds_eval = ds(path, ds_type, eval_tr)\n",
    "    if world_size == 1:\n",
    "        sampler = None\n",
    "    else:\n",
    "        sampler = torch.utils.data.distributed.DistributedSampler(ds_eval)\n",
    "    dl_eval = DataLoader(\n",
    "        dataset=ds_eval,\n",
    "        batch_size=100,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    model.eval()\n",
    "    e, y = eval_dataset(model, dl_eval)\n",
    "    y = y.cuda()\n",
    "    model.train()\n",
    "    return e, y\n",
    "\n",
    "def eval_dataset(model, dl):\n",
    "    all_xe, all_y = [], []\n",
    "    for x, y in dl:\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda(non_blocking=True)\n",
    "            e= model(x)\n",
    "            all_xe.append(e)\n",
    "        all_y.append(y)\n",
    "    return torch.cat(all_xe), torch.cat(all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a0c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 epochs.\n",
      "[0.38436866981769074, 0.5043889264010804, 0.6282916948008103, 0.7466239027683997, 0.8394665766374072, 0.9076637407157326]\n",
      "The recall before train:  0.38436866981769074\n",
      "[0.39010803511141123, 0.512322754895341, 0.6341998649561107, 0.7408845374746793, 0.8369345037137069, 0.9036124240378123]\n",
      "epoch: 0 recall:  0.39010803511141123\n",
      "best epoch: 0 best recall:  0.39010803511141123\n",
      "[0.37575962187711004, 0.5025320729237002, 0.6266036461850101, 0.7407157326130993, 0.8313639432815665, 0.9014179608372721]\n",
      "epoch: 1 recall:  0.37575962187711004\n",
      "best epoch: 0 best recall:  0.39010803511141123\n",
      "[0.37474679270763, 0.4952734638757596, 0.6287981093855503, 0.74949358541526, 0.8387913571910871, 0.9090141796083727]\n",
      "epoch: 2 recall:  0.37474679270763\n",
      "best epoch: 0 best recall:  0.39010803511141123\n",
      "[0.3663065496286293, 0.49155975692099935, 0.6166441593517893, 0.7343011478730588, 0.8269750168804861, 0.9009115462525321]\n",
      "epoch: 3 recall:  0.3663065496286293\n",
      "best epoch: 0 best recall:  0.39010803511141123\n",
      "[0.3885887913571911, 0.5064145847400405, 0.6286293045239703, 0.7412221471978393, 0.8313639432815665, 0.9017555705604321]\n",
      "epoch: 4 recall:  0.3885887913571911\n",
      "best epoch: 0 best recall:  0.39010803511141123\n",
      "[0.3847062795408508, 0.5067521944632005, 0.6244091829844699, 0.736664415935179, 0.8274814314652262, 0.900405131667792]\n",
      "epoch: 5 recall:  0.3847062795408508\n",
      "best epoch: 0 best recall:  0.39010803511141123\n",
      "[0.39112086428089127, 0.512491559756921, 0.6423024983119514, 0.7508440243079001, 0.8369345037137069, 0.9078325455773126]\n",
      "epoch: 6 recall:  0.39112086428089127\n",
      "best epoch: 6 best recall:  0.39112086428089127\n",
      "[0.37643484132343014, 0.5006752194463201, 0.6287981093855503, 0.7429101958136395, 0.8359216745442268, 0.9027683997299122]\n",
      "epoch: 7 recall:  0.37643484132343014\n",
      "best epoch: 6 best recall:  0.39112086428089127\n",
      "[0.38065496286293043, 0.5050641458474004, 0.6298109385550303, 0.7434166103983795, 0.8392977717758271, 0.9029372045914922]\n",
      "epoch: 8 recall:  0.38065496286293043\n",
      "best epoch: 6 best recall:  0.39112086428089127\n",
      "[0.3809925725860905, 0.5055705604321404, 0.62457798784605, 0.738183659689399, 0.8322079675894666, 0.9037812288993923]\n",
      "epoch: 9 recall:  0.3809925725860905\n",
      "best epoch: 6 best recall:  0.39112086428089127\n",
      "[0.3896016205266712, 0.5087778528021607, 0.6321742066171506, 0.7483119513841998, 0.8396353814989872, 0.9046252532072924]\n",
      "epoch: 10 recall:  0.3896016205266712\n",
      "best epoch: 6 best recall:  0.39112086428089127\n",
      "[0.37542201215395005, 0.5057393652937204, 0.6274476704929102, 0.7403781228899392, 0.8355840648210668, 0.9069885212694125]\n",
      "epoch: 11 recall:  0.37542201215395005\n",
      "best epoch: 6 best recall:  0.39112086428089127\n",
      "[0.3858879135719109, 0.5109723160027009, 0.6311613774476705, 0.7412221471978393, 0.8315327481431465, 0.9025995948683322]\n",
      "epoch: 12 recall:  0.3858879135719109\n",
      "best epoch: 6 best recall:  0.39112086428089127\n",
      "[0.3801485482781904, 0.5106347062795409, 0.6330182309250506, 0.7424037812288994, 0.8360904794058069, 0.9019243754220122]\n",
      "epoch: 13 recall:  0.3801485482781904\n",
      "best epoch: 6 best recall:  0.39112086428089127\n",
      "[0.3916272788656313, 0.5106347062795409, 0.6316677920324105, 0.7461174881836596, 0.8477380148548278, 0.9113774476704929]\n",
      "epoch: 14 recall:  0.3916272788656313\n",
      "best epoch: 14 best recall:  0.3916272788656313\n",
      "[0.3950033760972316, 0.5170492910195814, 0.638082376772451, 0.7506752194463201, 0.8401417960837272, 0.9080013504388926]\n",
      "epoch: 15 recall:  0.3950033760972316\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37947332883187035, 0.5128291694800811, 0.6350438892640108, 0.7478055367994598, 0.8386225523295071, 0.9039500337609723]\n",
      "epoch: 16 recall:  0.37947332883187035\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3727211343686698, 0.49679270762997974, 0.6294733288318703, 0.7388588791357191, 0.8342336259284268, 0.9014179608372721]\n",
      "epoch: 17 recall:  0.3727211343686698\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37964213369345035, 0.511647535449021, 0.6423024983119514, 0.761647535449021, 0.8511141120864281, 0.9083389601620526]\n",
      "epoch: 18 recall:  0.37964213369345035\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3865631330182309, 0.512322754895341, 0.6390952059419311, 0.75, 0.8440243079000675, 0.9128966914247131]\n",
      "epoch: 19 recall:  0.3865631330182309\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38149898717083053, 0.5075962187711006, 0.6401080351114112, 0.74966239027684, 0.8392977717758271, 0.9032748143146523]\n",
      "epoch: 20 recall:  0.38149898717083053\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3848750844024308, 0.5060769750168805, 0.62508440243079, 0.7371708305199189, 0.8355840648210668, 0.9010803511141121]\n",
      "epoch: 21 recall:  0.3848750844024308\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3779540850776502, 0.4989871708305199, 0.6293045239702904, 0.7390276839972991, 0.837440918298447, 0.9071573261309925]\n",
      "epoch: 22 recall:  0.3779540850776502\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.36293045239702904, 0.48953409858203917, 0.6191762322754896, 0.7344699527346388, 0.825962187711006, 0.900405131667792]\n",
      "epoch: 23 recall:  0.36293045239702904\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3848750844024308, 0.5060769750168805, 0.6279540850776503, 0.7442606347062796, 0.837778528021607, 0.9069885212694125]\n",
      "epoch: 24 recall:  0.3848750844024308\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38521269412559084, 0.5104659014179609, 0.6328494260634706, 0.7435854152599595, 0.8340648210668468, 0.9080013504388926]\n",
      "epoch: 25 recall:  0.38521269412559084\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38419986495611075, 0.5054017555705604, 0.636563133018231, 0.7527008777852802, 0.8470627954085078, 0.9152599594868333]\n",
      "epoch: 26 recall:  0.38419986495611075\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38436866981769074, 0.513335584064821, 0.636731937879811, 0.75033760972316, 0.8465563808237677, 0.9105334233625928]\n",
      "epoch: 27 recall:  0.38436866981769074\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3858879135719109, 0.5153612424037812, 0.6347062795408508, 0.7439230249831195, 0.8347400405131667, 0.9073261309925725]\n",
      "epoch: 28 recall:  0.3858879135719109\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37322754895340987, 0.49932478055367996, 0.6308237677245104, 0.7457798784604996, 0.8357528696826468, 0.9071573261309925]\n",
      "epoch: 29 recall:  0.37322754895340987\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3820054017555706, 0.5106347062795409, 0.6345374746792708, 0.7540513166779204, 0.8408170155300473, 0.9064821066846726]\n",
      "epoch: 30 recall:  0.3820054017555706\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3740715732613099, 0.5008440243079001, 0.6220459149223497, 0.738014854827819, 0.8320391627278866, 0.9029372045914922]\n",
      "epoch: 31 recall:  0.3740715732613099\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3887575962187711, 0.5050641458474004, 0.6266036461850101, 0.737508440243079, 0.8349088453747467, 0.9068197164078325]\n",
      "epoch: 32 recall:  0.3887575962187711\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3926401080351114, 0.5155300472653612, 0.6347062795408508, 0.7442606347062796, 0.8333896016205267, 0.9024307900067522]\n",
      "epoch: 33 recall:  0.3926401080351114\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37187711006076973, 0.4991559756920999, 0.6217083051991897, 0.7343011478730588, 0.8278190411883862, 0.8975354490209319]\n",
      "epoch: 34 recall:  0.37187711006076973\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37744767049291017, 0.5021944632005402, 0.6193450371370696, 0.7405469277515192, 0.8325455773126266, 0.899898717083052]\n",
      "epoch: 35 recall:  0.37744767049291017\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.36866981769074947, 0.49577987846049965, 0.6233963538149899, 0.7445982444294396, 0.837947332883187, 0.9080013504388926]\n",
      "epoch: 36 recall:  0.36866981769074947\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37930452397029035, 0.5042201215395004, 0.6267724510465902, 0.7430790006752195, 0.8409858203916273, 0.9063133018230926]\n",
      "epoch: 37 recall:  0.37930452397029035\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37677245104659013, 0.5013504388926401, 0.6220459149223497, 0.7351451721809588, 0.8327143821742066, 0.9066509115462525]\n",
      "epoch: 38 recall:  0.37677245104659013\n",
      "best epoch: 15 best recall:  0.3950033760972316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38723835246455096, 0.5141796083727211, 0.637407157326131, 0.7483119513841998, 0.8421674544226874, 0.9113774476704929]\n",
      "epoch: 39 recall:  0.38723835246455096\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37964213369345035, 0.5052329507089804, 0.6333558406482107, 0.7508440243079001, 0.8389601620526671, 0.9056380823767725]\n",
      "epoch: 40 recall:  0.37964213369345035\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38335584064821066, 0.5048953409858203, 0.6286293045239703, 0.7405469277515192, 0.8359216745442268, 0.9076637407157326]\n",
      "epoch: 41 recall:  0.38335584064821066\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38825118163403105, 0.511816340310601, 0.6321742066171506, 0.7491559756920999, 0.8396353814989872, 0.9061444969615124]\n",
      "epoch: 42 recall:  0.38825118163403105\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3816677920324105, 0.5067521944632005, 0.6321742066171506, 0.7471303173531397, 0.8349088453747467, 0.9025995948683322]\n",
      "epoch: 43 recall:  0.3816677920324105\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3887575962187711, 0.5145172180958811, 0.6353814989871708, 0.7462862930452397, 0.8396353814989872, 0.9032748143146523]\n",
      "epoch: 44 recall:  0.3887575962187711\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38318703578663066, 0.5062457798784605, 0.6240715732613099, 0.7422349763673194, 0.8396353814989872, 0.9063133018230926]\n",
      "epoch: 45 recall:  0.38318703578663066\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3857191087103309, 0.5047265361242403, 0.6347062795408508, 0.7451046590141797, 0.8394665766374072, 0.9093517893315327]\n",
      "epoch: 46 recall:  0.3857191087103309\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38048615800135044, 0.5069209993247805, 0.636563133018231, 0.7478055367994598, 0.8419986495611074, 0.9068197164078325]\n",
      "epoch: 47 recall:  0.38048615800135044\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3811613774476705, 0.5055705604321404, 0.6296421336934503, 0.7435854152599595, 0.8386225523295071, 0.899729912221472]\n",
      "epoch: 48 recall:  0.3811613774476705\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3889264010803511, 0.5086090479405807, 0.62457798784605, 0.7402093180283592, 0.8352464550979068, 0.9105334233625928]\n",
      "epoch: 49 recall:  0.3889264010803511\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.387407157326131, 0.5087778528021607, 0.638419986495611, 0.7483119513841998, 0.837272113436867, 0.9080013504388926]\n",
      "epoch: 50 recall:  0.387407157326131\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3835246455097907, 0.5092842673869007, 0.6321742066171506, 0.7462862930452397, 0.8384537474679271, 0.9128966914247131]\n",
      "epoch: 51 recall:  0.3835246455097907\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38538149898717083, 0.5114787305874409, 0.6330182309250506, 0.7484807562457799, 0.8401417960837272, 0.9081701553004726]\n",
      "epoch: 52 recall:  0.38538149898717083\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37660364618501013, 0.5065833896016205, 0.6306549628629304, 0.7447670492910196, 0.8406482106684673, 0.9128966914247131]\n",
      "epoch: 53 recall:  0.37660364618501013\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38706954760297096, 0.5109723160027009, 0.6313301823092505, 0.7459486833220796, 0.8371033085752869, 0.9069885212694125]\n",
      "epoch: 54 recall:  0.38706954760297096\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38909520594193114, 0.5111411208642809, 0.637575962187711, 0.7515192437542201, 0.8458811613774476, 0.9135719108710331]\n",
      "epoch: 55 recall:  0.38909520594193114\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3836934503713707, 0.5042201215395004, 0.6260972316002701, 0.7435854152599595, 0.837609723160027, 0.9073261309925725]\n",
      "epoch: 56 recall:  0.3836934503713707\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3808237677245105, 0.5033760972316003, 0.6284604996623903, 0.7413909520594193, 0.8340648210668468, 0.9053004726536125]\n",
      "epoch: 57 recall:  0.3808237677245105\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37744767049291017, 0.50016880486158, 0.6289669142471304, 0.7344699527346388, 0.8328831870357867, 0.9036124240378123]\n",
      "epoch: 58 recall:  0.37744767049291017\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3777852802160702, 0.50033760972316, 0.6272788656313302, 0.7434166103983795, 0.8352464550979068, 0.9064821066846726]\n",
      "epoch: 59 recall:  0.3777852802160702\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38335584064821066, 0.5047265361242403, 0.6347062795408508, 0.7521944632005402, 0.8431802835921675, 0.9108710330857529]\n",
      "epoch: 60 recall:  0.38335584064821066\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3776164753544902, 0.5008440243079001, 0.62491559756921, 0.7449358541525996, 0.8337272113436867, 0.9046252532072924]\n",
      "epoch: 61 recall:  0.3776164753544902\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38048615800135044, 0.5028696826468603, 0.6274476704929102, 0.7405469277515192, 0.8300135043889264, 0.9032748143146523]\n",
      "epoch: 62 recall:  0.38048615800135044\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.39112086428089127, 0.511647535449021, 0.6345374746792708, 0.7435854152599595, 0.837609723160027, 0.9056380823767725]\n",
      "epoch: 63 recall:  0.39112086428089127\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3848750844024308, 0.512322754895341, 0.6453409858203917, 0.7521944632005402, 0.8396353814989872, 0.9091829844699527]\n",
      "epoch: 64 recall:  0.3848750844024308\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37930452397029035, 0.511647535449021, 0.6296421336934503, 0.7403781228899392, 0.8271438217420661, 0.8988858879135719]\n",
      "epoch: 65 recall:  0.37930452397029035\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38318703578663066, 0.513673193787981, 0.6394328156650911, 0.7513504388926401, 0.8423362592842674, 0.9039500337609723]\n",
      "epoch: 66 recall:  0.38318703578663066\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3885887913571911, 0.5072586090479406, 0.6311613774476705, 0.7462862930452397, 0.8369345037137069, 0.9061444969615124]\n",
      "epoch: 67 recall:  0.3885887913571911\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38690074274139097, 0.5126603646185011, 0.6311613774476705, 0.7430790006752195, 0.8335584064821067, 0.9027683997299122]\n",
      "epoch: 68 recall:  0.38690074274139097\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3809925725860905, 0.4939230249831195, 0.6235651586765699, 0.7319378798109386, 0.8317015530047266, 0.9053004726536125]\n",
      "epoch: 69 recall:  0.3809925725860905\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3700202565833896, 0.4989871708305199, 0.6287981093855503, 0.738014854827819, 0.838116137744767, 0.9029372045914922]\n",
      "epoch: 70 recall:  0.3700202565833896\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3858879135719109, 0.5081026333558406, 0.6259284267386901, 0.7408845374746793, 0.8359216745442268, 0.9056380823767725]\n",
      "epoch: 71 recall:  0.3858879135719109\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38841998649561105, 0.511985145172181, 0.6348750844024308, 0.7456110735989196, 0.8323767724510466, 0.9064821066846726]\n",
      "epoch: 72 recall:  0.38841998649561105\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.39027683997299123, 0.5162052667116813, 0.6291357191087104, 0.738014854827819, 0.8296758946657664, 0.9019243754220122]\n",
      "epoch: 73 recall:  0.39027683997299123\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3835246455097907, 0.5065833896016205, 0.6227211343686698, 0.7354827819041189, 0.8315327481431465, 0.9012491559756921]\n",
      "epoch: 74 recall:  0.3835246455097907\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3799797434166104, 0.5060769750168805, 0.6281228899392303, 0.7445982444294396, 0.8389601620526671, 0.9056380823767725]\n",
      "epoch: 75 recall:  0.3799797434166104\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37930452397029035, 0.5079338284942606, 0.6357191087103309, 0.7469615124915597, 0.8367656988521269, 0.9071573261309925]\n",
      "epoch: 76 recall:  0.37930452397029035\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3809925725860905, 0.5081026333558406, 0.6379135719108711, 0.7510128291694801, 0.837947332883187, 0.9009115462525321]\n",
      "epoch: 77 recall:  0.3809925725860905\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3818365968939905, 0.5077650236326806, 0.6323430114787306, 0.7447670492910196, 0.8403106009453072, 0.9090141796083727]\n",
      "epoch: 78 recall:  0.3818365968939905\n",
      "best epoch: 15 best recall:  0.3950033760972316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38521269412559084, 0.5104659014179609, 0.6296421336934503, 0.7418973666441594, 0.8352464550979068, 0.9068197164078325]\n",
      "epoch: 79 recall:  0.38521269412559084\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37457798784604995, 0.5020256583389602, 0.6330182309250506, 0.7472991222147198, 0.8421674544226874, 0.9110398379473329]\n",
      "epoch: 80 recall:  0.37457798784604995\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3885887913571911, 0.5089466576637407, 0.6299797434166104, 0.7422349763673194, 0.8327143821742066, 0.9031060094530723]\n",
      "epoch: 81 recall:  0.3885887913571911\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38234301147873057, 0.5016880486158002, 0.6301485482781904, 0.7467927076299797, 0.8416610398379474, 0.9088453747467927]\n",
      "epoch: 82 recall:  0.38234301147873057\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38419986495611075, 0.5096218771100608, 0.6360567184334909, 0.7457798784604996, 0.8322079675894666, 0.8975354490209319]\n",
      "epoch: 83 recall:  0.38419986495611075\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37660364618501013, 0.49426063470627957, 0.6176569885212694, 0.737846049966239, 0.8322079675894666, 0.9019243754220122]\n",
      "epoch: 84 recall:  0.37660364618501013\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3835246455097907, 0.5028696826468603, 0.6237339635381499, 0.738183659689399, 0.8327143821742066, 0.9024307900067522]\n",
      "epoch: 85 recall:  0.3835246455097907\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3820054017555706, 0.5067521944632005, 0.6217083051991897, 0.7420661715057394, 0.8325455773126266, 0.9037812288993923]\n",
      "epoch: 86 recall:  0.3820054017555706\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.36951384199864956, 0.5020256583389602, 0.6272788656313302, 0.7434166103983795, 0.8338960162052668, 0.9034436191762323]\n",
      "epoch: 87 recall:  0.36951384199864956\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3820054017555706, 0.5055705604321404, 0.6239027683997299, 0.7403781228899392, 0.8325455773126266, 0.9009115462525321]\n",
      "epoch: 88 recall:  0.3820054017555706\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38318703578663066, 0.513335584064821, 0.6316677920324105, 0.7479743416610398, 0.8389601620526671, 0.9063133018230926]\n",
      "epoch: 89 recall:  0.38318703578663066\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.39010803511141123, 0.5099594868332208, 0.6287981093855503, 0.7481431465226198, 0.8357528696826468, 0.9009115462525321]\n",
      "epoch: 90 recall:  0.39010803511141123\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3924713031735314, 0.5168804861580013, 0.6340310600945307, 0.7493247805536799, 0.8462187711006077, 0.9101958136394328]\n",
      "epoch: 91 recall:  0.3924713031735314\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38133018230925053, 0.5038825118163404, 0.6282916948008103, 0.75050641458474, 0.8317015530047266, 0.9049628629304524]\n",
      "epoch: 92 recall:  0.38133018230925053\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.37491559756921, 0.5043889264010804, 0.6321742066171506, 0.738183659689399, 0.8360904794058069, 0.9086765698852127]\n",
      "epoch: 93 recall:  0.37491559756921\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.387575962187711, 0.5160364618501013, 0.6357191087103309, 0.7493247805536799, 0.8408170155300473, 0.9074949358541526]\n",
      "epoch: 94 recall:  0.387575962187711\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.387744767049291, 0.5092842673869007, 0.6338622552329507, 0.7456110735989196, 0.8394665766374072, 0.9115462525320729]\n",
      "epoch: 95 recall:  0.387744767049291\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3789669142471303, 0.5027008777852802, 0.6274476704929102, 0.7440918298446996, 0.8349088453747467, 0.9068197164078325]\n",
      "epoch: 96 recall:  0.3789669142471303\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38318703578663066, 0.5050641458474004, 0.6276164753544902, 0.7430790006752195, 0.837272113436867, 0.9069885212694125]\n",
      "epoch: 97 recall:  0.38318703578663066\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.3723835246455098, 0.5055705604321404, 0.6282916948008103, 0.7449358541525996, 0.838116137744767, 0.9019243754220122]\n",
      "epoch: 98 recall:  0.3723835246455098\n",
      "best epoch: 15 best recall:  0.3950033760972316\n",
      "[0.38538149898717083, 0.5129979743416611, 0.6379135719108711, 0.7452734638757597, 0.8382849426063471, 0.9078325455773126]\n",
      "epoch: 99 recall:  0.38538149898717083\n",
      "best epoch: 15 best recall:  0.3950033760972316\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(gpu_id)\n",
    "world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "\n",
    "train_tr = dataset.utils.make_transform(\n",
    "    is_train = True, \n",
    "    is_inception = (model == 'bn_inception')\n",
    ")\n",
    "\n",
    "ds_list = {\"CUB\": CUBirds, \"SOP\": SOP, \"Cars\": Cars, \"Inshop\": Inshop_Dataset}\n",
    "ds_class = ds_list[ds]\n",
    "ds_train = ds_class(path, \"train\", train_tr)\n",
    "\n",
    "sampler = UniqueClassSempler(\n",
    "    ds_train.ys, num_samples, local_rank, world_size\n",
    ")\n",
    "dl_train = DataLoader(\n",
    "    dataset=ds_train,\n",
    "    sampler=sampler,\n",
    "    batch_size=bs,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "if model.find('resnet18')+1:\n",
    "    model = Resnet18(embedding_size=emb, pretrained=True, bn_freeze = bn_freeze).cuda().train() \n",
    "loss_f = partial(contrastive_loss, tau=t)\n",
    "\n",
    "get_emb_f = partial(\n",
    "    get_emb,\n",
    "    model=model,\n",
    "    ds=ds_class,\n",
    "    path=path,\n",
    "    num_workers=workers,\n",
    "    world_size=world_size,\n",
    ")\n",
    "if freezer == True:\n",
    "    embedding_param = list(model.model.embedding.parameters())\n",
    "    for param in list(set(model.parameters()).difference(set(embedding_param))):\n",
    "        param.requires_grad = False\n",
    "    optimizer = optim.AdamW(embedding_param, lr=lr)\n",
    "else:\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_decay_step, gamma = lr_decay_gamma)\n",
    "print(\"Training for {} epochs.\".format(ep))\n",
    "\n",
    "r0= evaluate(get_emb_f, ds)\n",
    "print(\"The recall before train: \", r0)\n",
    "\n",
    "losses_list = []\n",
    "best_recall= 0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(0, ep):\n",
    "    model.train()\n",
    "    if bn_freeze:\n",
    "        modules = model.model.modules()\n",
    "        for m in modules: \n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    losses_per_epoch = []\n",
    "    sampler.set_epoch(epoch)\n",
    "    stats_ep = []\n",
    "    for x, y in dl_train:\n",
    "        y = y.view(len(y) // num_samples, num_samples)\n",
    "        assert (y[:, 0] == y[:, -1]).all()\n",
    "        s1 = y[:, 0].tolist()\n",
    "        assert len(set(s1)) == len(s1)\n",
    "\n",
    "        x = x.cuda(non_blocking=True)\n",
    "        e = model(x)\n",
    "        e = e.view(len(x) // num_samples, num_samples, emb)\n",
    "        loss = 0\n",
    "        for i in range(num_samples):\n",
    "            for j in range(num_samples):\n",
    "                if i != j:\n",
    "                    l, st = loss_f(e[:, i], e[:, j])\n",
    "                    loss += l\n",
    "                    stats_ep.append({**st, \"loss\": l.item()})\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()        \n",
    "    rh= evaluate(get_emb_f, ds)\n",
    "    stats_ep = {k: np.mean([x[k] for x in stats_ep]) for k in stats_ep[0]}\n",
    "    stats_ep = {\"recall\": rh, **stats_ep}\n",
    "    if rh > best_recall :\n",
    "        best_recall = rh\n",
    "        best_epoch = epoch\n",
    "    print(\"epoch:\",epoch,\"recall: \", rh)\n",
    "    print(\"best epoch:\",best_epoch,\"best recall: \", best_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1435d1df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
